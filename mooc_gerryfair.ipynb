{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GerryFair Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required Data Format\n",
    "\n",
    "In order to train and audit for bias, we require three dataframes. The first two are the standard `X` and `Y`, which are the samples and their labels respectively. These should be one-hot-encoded. The third required dataframe is the list of protected attributes. This contain the values of the protected attributes for each row in the sample. These will be the attributes that we will audit for bias towards. Please note that we do not promise to protect against bias towards attributes that are not included in this list.\n",
    "\n",
    "#### Cleaning Data\n",
    "If your data is not in that format, it needs to be cleaned. We provide a method, `clean_data` in *clean.py*, you can use to clean your data into the accepted format.\n",
    "\n",
    "The variable `dataset` should hold the file path to the file containing the dataset. The variable `attributes` should hold the file path to the file containing protected attributes. This should simply be one row where a column is 2 if it is the label, 1 if it is protected, and 0 otherwise. You should set `centered` to be `True` if you want the data to be centered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label feature: ['completed']\n",
      "sensitive features: ['country_cd_US', 'is_female', 'bachelor_obtained', 'white']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "drop() takes from 1 to 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\a006x2\\Desktop\\gerryfair_2\\algofair\\mooc_gerryfair.ipynb Cell 3\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/a006x2/Desktop/gerryfair_2/algofair/mooc_gerryfair.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m attributes \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m./data/protected.csv\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/a006x2/Desktop/gerryfair_2/algofair/mooc_gerryfair.ipynb#W2sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m centered \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/a006x2/Desktop/gerryfair_2/algofair/mooc_gerryfair.ipynb#W2sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m X, X_prime, y \u001b[39m=\u001b[39m gerryfair\u001b[39m.\u001b[39;49mclean\u001b[39m.\u001b[39;49mclean_dataset(dataset, attributes, centered)\n",
      "File \u001b[1;32mc:\\Users\\a006x2\\Desktop\\gerryfair_2\\algofair\\gerryfair\\clean.py:48\u001b[0m, in \u001b[0;36mclean_dataset\u001b[1;34m(dataset, attributes, centered)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39msensitive features: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(sens_cols))\n\u001b[0;32m     47\u001b[0m sens_dict \u001b[39m=\u001b[39m {c: \u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m c \u001b[39min\u001b[39;00m sens_cols \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m df\u001b[39m.\u001b[39mcolumns}\n\u001b[1;32m---> 48\u001b[0m X, sens_dict \u001b[39m=\u001b[39m one_hot_code(X, sens_dict)\n\u001b[0;32m     49\u001b[0m sens_names \u001b[39m=\u001b[39m [key \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m sens_dict\u001b[39m.\u001b[39mkeys() \u001b[39mif\u001b[39;00m sens_dict[key] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m]\n\u001b[0;32m     50\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mthere are \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m sensitive features including derivative features\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mlen\u001b[39m(sens_names)))\n",
      "File \u001b[1;32mc:\\Users\\a006x2\\Desktop\\gerryfair_2\\algofair\\gerryfair\\clean.py:75\u001b[0m, in \u001b[0;36mone_hot_code\u001b[1;34m(df1, sens_dict)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(df1[c][\u001b[39m0\u001b[39m], \u001b[39mstr\u001b[39m):\n\u001b[0;32m     74\u001b[0m     column \u001b[39m=\u001b[39m df1[c]\n\u001b[1;32m---> 75\u001b[0m     df1 \u001b[39m=\u001b[39m df1\u001b[39m.\u001b[39;49mdrop(c, \u001b[39m1\u001b[39;49m)\n\u001b[0;32m     76\u001b[0m     unique_values \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mset\u001b[39m(column))\n\u001b[0;32m     77\u001b[0m     n \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(unique_values)\n",
      "\u001b[1;31mTypeError\u001b[0m: drop() takes from 1 to 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "import gerryfair\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "dataset = \"./data/preprocessed.csv\"\n",
    "attributes = \"./data/protected.csv\"\n",
    "centered = True\n",
    "X, X_prime, y = gerryfair.clean.clean_dataset(dataset, attributes, centered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using tools to train a model\n",
    "\n",
    "Now, we can use the `Model` class in order to train a new model. When instatiating the object, you may provide any options that you will want when training the classifier. If you wish to change the options, you may use the `set_options` method. Both are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 15\n",
    "printflag = True\n",
    "gamma = .01\n",
    "fair_model = gerryfair.model.Model(C=C, printflag=printflag, gamma=gamma)\n",
    "max_iters = 50\n",
    "fair_model.set_options(max_iters=max_iters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we are happy with the options, we can use the `train` method to train a classifier using the Fictitious Play algorithm described in [the original paper](https://arxiv.org/abs/1711.05144v3). We will need our three dataframes from earlier. We also return the final errors and fp_difference from training.\n",
    "\n",
    "I will first split `X` and `y` into a training and a testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Set\n",
    "X_train = X.iloc[:X.shape[0]-50]\n",
    "X_prime_train = X_prime.iloc[:X_prime.shape[0]-50]\n",
    "y_train = y.iloc[:y.shape[0]-50]\n",
    "# Test Set\n",
    "X_test = X.iloc[-50:].reset_index(drop=True)\n",
    "X_prime_test = X_prime.iloc[-50:].reset_index(drop=True)\n",
    "y_test = y.iloc[-50:].reset_index(drop=True)\n",
    "\n",
    "# Train the model\n",
    "[errors, fp_difference] = fair_model.train(X_train, X_prime_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use our model to make out of sample predictions. This can be done using the `predict` method of the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = fair_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using tools on evaluate a generic model\n",
    "\n",
    "Once we have a model, whether it is fictitious play model or any generic model, we can use our tools to evaluate the fairness in several ways.\n",
    "\n",
    "#### Auditing Predictions\n",
    "\n",
    "You can audit for subgroup fairness of your predictions using the functionality within the `audit` object. These predictions can come from any arbitrary model. Auditing the predictions returns the group that failed the audit and gamma unfairness of the predictions on that group. We will be using our predictions from the previous part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auditor = gerryfair.model.Auditor()\n",
    "[group, gamma_unfairness] = auditor.audit(predictions, X_prime_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting errors\n",
    "You can also plot the errors of the model during training using the `plot_single` function in *fairness_plots.py*. Please note that these errors are returned by our fictitious play algorithm, so this is specifically for analyzing the effectiveness of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gerryfair.fairness_plots.plot_single(errors, fp_difference, max_iters, gamma, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fair_model._fictitious_play(X_test, X_prime_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
